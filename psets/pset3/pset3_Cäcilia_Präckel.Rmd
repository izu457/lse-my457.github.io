---
title: "MY457: Problem Set 3"
date:  "`r format(Sys.time(), '%a/%d/%b')`"
author: "L. Cäcilia Präckel"
always_allow_html: true
output: 
  bookdown::pdf_document2:
    toc: false
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, linewidth=60)

# you can include your libraries here:
library(tidyverse)

# and any other options in R:
options(scipen=999)

```


1 Concepts

1.1
In a study with a binary treatment and two measured points in time, we can observe the following realised outcomes:

${Z_i0=0}$ for ${G_i=1}$ - the realised outcome of the treatment group before treatment, at time 0

${Z_i1=0}$ for ${G_i=0}$ - the realised outcome of the control group at time 0

${Z_i1=1}$ for ${G_i=1}$ - the realised outcome of the treatment group after treatment, at time 1

${Z_i0=1}$ for ${G_i=0}$ - the realised outcome for the control group at time 1 (still untreated)

1.2
The main assumption in a two-period difference-in-differences model is the parallel trends assumption. This assumption states that the ATE for the treated is the same as the ATE for the control group in the absence of treatment. This assumption is necessary to identify the average treatment effect for the treated. The parallel trends assumption can be tested by comparing the pre-treatment trends of the treatment and control group. If the trends are parallel, the assumption is met. If the trends are not parallel, the assumption is violated and the difference-in-differences estimator will be biased. This means, the ATE for the treated will not be identified.

1.3
Parameters in the following regression model:
${Y_i1(1) = \hat{\alpha} + \hat{\gamma} G_i + \hat{\delta} T_i + \hat{\tau}(G_i * T_i) + \hat{\epsilon_i}}$

- $\hat{\alpha}$ is the intercept, defining the change of Y if no treatment is applied

- $\hat{\gamma}$ is the coefficient for the control group, defining the change of Y if no treatment is applied

- $\hat{\delta}$ is the coefficient for the treatment group, defining the change of Y if treatment is applied

- $\hat{\tau}$ is the coefficient for the interaction term, defining the change of Y if treatment is applied to the treatment group

- $\hat{\epsilon_i}$ is the error term


2 Simulations

2.1
The code of the assignment (see annex) describes a difference-in-differences data generation process of 1.000 units and an expected causal effect of 25.000.
To define the treatment and control groups, a binary group indicator G is defined with a 50% probabllity to indicate 1.
By looping twice over the creation of a data frame, for both treatment and control group a dataframe is created with three columns: an individual ID for each unit, the group indicator G and the treatment indicator T. Both data frames are combined to one data frame "sim_data".
The potential outcome Y0 is generated with a normal distribution of the n units with a mean of 50.000 and a standard deviation of 2.500.
The potential outcome Y1 is generated by adding the causal effect tau to Y0.
The realised outcome Y is generated by taking the potential outcome Y0 if the unit is in the control group and the potential outcome Y1 if the unit is in the treatment group.
Yo, Y1, and Y are appended to the data frame.

The resulting data represents panel data because it contains two observations for each unit, representing the unit at two points in time.
Repeated cross-section would imply that the data is collected from different samples of units at different points in time and each unit would be observed only once.

```{r, echo = FALSE}
# Difference-in-differences data generation process
set.seed(123)

n_units <- 1000
tau <- 25000
G = rbinom(n_units, 1, 0.5)
for (i in 1:2) {
data <- tibble(
ID = 1:n_units,
G = G,
T = ifelse(i == 2, 1, 0)
)
if (i == 1) {
sim_data <- data
} else {
sim_data <- rbind(sim_data, data)
}
}
Y0 <- rnorm(n_units, 50000, 2500)
data <- sim_data %>% mutate(
Y0 = c(Y0, Y0*(1+1/10)),
Y0 = ifelse(G == 1, Y0 + 10000, Y0),
Y1 = Y0 + tau,
Y = ifelse(G == 1 & T == 1, Y1, Y0)
)
```


2.2
```{r}
# Estimating the difference-in-differences without a linear regression but using only Y, G, and t

# Average treatment effect
ATE <- mean(data$Y[data$G == 1 & data$T == 1]) - mean(data$Y[data$G == 1 & data$T == 0]) - (mean(data$Y[data$G == 0 & data$T == 1]) - mean(data$Y[data$G == 0 & data$T == 0]))
ATE

# Standard error
SE <- sqrt(var(data$Y[data$G == 1 & data$T == 1])/sum(data$G == 1 & data$T == 1) + var(data$Y[data$G == 1 & data$T == 0])/sum(data$G == 1 & data$T == 0) + var(data$Y[data$G == 0 & data$T == 1])/sum(data$G == 0 & data$T == 1) + var(data$Y[data$G == 0 & data$T == 0])/sum(data$G == 0 & data$T == 0))
SE

# Confidence interval
CI <- c(ATE - 1.96*SE, ATE + 1.96*SE)
CI

# P-value
P <- 2*pnorm(-abs(ATE/SE))
P

# Power
Power <- 1 - pnorm(1.96 - abs(ATE/SE))
Power

# Effect size
ES <- ATE/SE
ES

# Sample size
n <- sum(data$G == 1 & data$T == 1) + sum(data$G == 1 & data$T == 0) + sum(data$G == 0 & data$T == 1) + sum(data$G == 0 & data$T == 0)
n
```

2.3
Estimating the difference-in-differences with a linear regression leads to the same estimation of the ATE and only very slight differences in the standard deviation. This is not surprising because the difference-in-differences estimator is the same as the coefficient of the interaction term in the linear regression model.
(?)

```{r}
# Estimating the difference-in-differences with a linear regression

# Difference-in-differences estimator
lm(Y ~ G + T + G*T, data = data) %>% summary()

# Average treatment effect
ATE <- lm(Y ~ G + T + G*T, data = data) %>% summary() %>% coef() %>% .[4]
ATE

# Standard error
SE <- lm(Y ~ G + T + G*T, data = data) %>% summary() %>% coef() %>% .[4, 2]
SE
```

2.4
```{r visulaising the diff-in-diff estimator}
# Visualising the difference-in-differences estimator
ggplot(data, aes(x = T, y = Y, color = factor(G))) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Difference-in-differences estimator", x = "Treatment", y = "Outcome", color = "Group")

```

2.5
Different from the previous data generation process, this code (see annex) generates  ...

```{r new generation process, eval = FALSE}

set.seed(123)
n_obs <- 1000
n_periods <- 20
tau_values <- c(1000, 3000, 3000, 2000, 5000, 3000, 9000, 6000, 7000, 10000,
9000, 8000, 6000, 3000, 7000, 2000, 5000, 2000, 1000)
tau <- setNames(tau_values, paste0("tau_", 1:19))
G = rbinom(n_obs, 1, 0.5)

for (i in 1:20) {
treated_units <- ifelse(i > 5, sample(1:n_obs, size = floor(1/40*n_obs)), NA)
if (i == 1) {
treated <- treated_units
} else {
treated <- c(treated, treated_units)
}
data <- tibble(
ID = 1:n_obs,
G = G,
P = i,
T = ifelse(ID %in% treated, 1, 0)
)
if (i == 1) {
sim_data <- data
} else {
sim_data <- rbind(sim_data, data)
}
}
Y0 <- rnorm(n_obs, 50000, 2500)
sim_data <- sim_data %>%
mutate(
Y0 = (1 + P/10) * Y0 + if_else(G == 1, 10000, 0),
Y1 = case_when(
P %in% 1:19 ~ Y0 + tau[paste0("tau_", P)],
TRUE ~ Y0
),
Y = if_else(G == 1 & T == 1, Y1, Y0),
D = T * G
)
data <- sim_data

```


2.6
```{r TWFE, eval = FALSE}
# Estimating the difference-in-differences with a two-way fixed-effects linear regression

# Difference-in-differences estimator
lm(Y ~ D + factor(ID) + factor(P), data = data) %>% summary()

# Average treatment effect
ATE <- lm(Y ~ D + factor(ID) + factor(P), data = data) %>% summary() %>% coef() %>% .[2]
ATE

# Standard error
SE <- lm(Y ~ D + factor(ID) + factor(P), data = data) %>% summary() %>% coef() %>% .[2, 2]
```


2.7



\clearpage
# Code appendix
```{r ref.label = knitr::all_labels(), echo=TRUE, eval=FALSE}
# this chunk generates the complete code appendix. 
# eval=FALSE tells R not to re-run (``evaluate'') the code here. 
```